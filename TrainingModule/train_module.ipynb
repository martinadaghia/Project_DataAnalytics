{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importazione librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento file train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../../train.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controllo  e rimozione valori nulli e duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valori mancanti per ciascuna colonna\n",
    "missing_values_per_column = df.isnull().sum()\n",
    "print(\"\\nValori mancanti nel DataFrame per ciascuna colonna:\")\n",
    "print(missing_values_per_column)\n",
    "\n",
    "# Totale dei valori mancanti in tutto il DataFrame\n",
    "total_missing_values = missing_values_per_column.sum()\n",
    "print(f\"\\nTotale dei valori mancanti nel DataFrame:\\n{total_missing_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDuplicati nel DataFrame:\")\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.dropna() \n",
    "clean_df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica rimozione valori nulli e duplicati\n",
    "total_missing_values = missing_values_per_column.sum()\n",
    "print(f\"\\nTotale dei valori mancanti nel DataFrame: {total_missing_values}\")\n",
    "print(f\"\\nDuplicati nel DataFrame: {clean_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rimozione outlier e visualizzazione post rimozione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itera su ogni anno presente nel DataFrame\n",
    "for year in clean_df['Year'].unique():\n",
    "    # Filtra il DataFrame per l'anno corrente\n",
    "    df_year = clean_df[clean_df['Year'] == year]\n",
    "    \n",
    "    # Calcola la mediana per ogni colonna\n",
    "    median_values = df_year.median()\n",
    "    \n",
    "    # Calcola i limiti per individuare gli outlier per ogni colonna\n",
    "    Q1 = df_year.quantile(0.25)\n",
    "    Q3 = df_year.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Sostituisci gli outlier con la mediana per ogni colonna\n",
    "    def replace_outliers(row):\n",
    "        for col in df_year.columns[1:]:  # Escludi la colonna 'year'\n",
    "            if row[col] < lower_limit[col] or row[col] > upper_limit[col]:\n",
    "                row[col] = median_values[col]\n",
    "        return row\n",
    "    \n",
    "    df_year = df_year.apply(replace_outliers, axis=1) # Sostituzione outlier con mediana\n",
    "    \n",
    "    # Sostituisci i dati nel DataFrame originale\n",
    "    clean_df.loc[clean_df['Year'] == year] = df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleziona solo le colonne che iniziano con 'S'\n",
    "colonne_s = [col for col in clean_df.columns if col.startswith('S')]\n",
    "\n",
    "# Lista per memorizzare i risultati originali e nuovi\n",
    "risultati_outliers = []\n",
    "risultati_nuovi_outliers = []\n",
    "\n",
    "# Ciclo attraverso ogni colonna 'S'\n",
    "for col in colonne_s:\n",
    "    # Calcola i quantili e l'IQR (Interquartile Range) per i dati originali\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    \n",
    "    # Calcola i baffi inferiori e superiori\n",
    "    baffo_inferiore = q1 - 1.5 * iqr\n",
    "    baffo_superiore = q3 + 1.5 * iqr\n",
    "    \n",
    "    # Trova gli outliers inferiori e superiori per i dati originali\n",
    "    outliers_inferiori = df[df[col] < baffo_inferiore]\n",
    "    outliers_superiori = df[df[col] > baffo_superiore]\n",
    "    numero_outliers = len(outliers_inferiori) + len(outliers_superiori)\n",
    "    \n",
    "    # Calcola la percentuale di outliers\n",
    "    percentuale_outliers = (numero_outliers / len(df)) * 100\n",
    "    \n",
    "    # Aggiungi i risultati alla lista\n",
    "    risultati_outliers.append({\n",
    "        'Colonna': col,\n",
    "        'Numero outliers': numero_outliers,\n",
    "        'Percentuale outliers': f'{percentuale_outliers:.2f}%'\n",
    "    })\n",
    "    \n",
    "    # Calcola i quantili e l'IQR (Interquartile Range) per i dati modificati\n",
    "    q1_new = clean_df[col].quantile(0.25)\n",
    "    q3_new = clean_df[col].quantile(0.75)\n",
    "    iqr_new = q3_new - q1_new\n",
    "    \n",
    "    # Calcola i baffi inferiori e superiori per i dati modificati\n",
    "    baffo_inferiore_new = q1_new - 1.5 * iqr_new\n",
    "    baffo_superiore_new = q3_new + 1.5 * iqr_new\n",
    "    \n",
    "    # Trova gli outliers inferiori e superiori per i dati modificati\n",
    "    outliers_inferiori_new = clean_df[clean_df[col] < baffo_inferiore_new]\n",
    "    outliers_superiori_new = clean_df[clean_df[col] > baffo_superiore_new]\n",
    "    numero_outliers_new = len(outliers_inferiori_new) + len(outliers_superiori_new)\n",
    "    \n",
    "    # Calcola la percentuale di nuovi outliers\n",
    "    percentuale_outliers_new = (numero_outliers_new / len(clean_df)) * 100\n",
    "    \n",
    "    # Aggiungi i risultati alla lista dei nuovi outliers\n",
    "    risultati_nuovi_outliers.append({\n",
    "        'Colonna': col,\n",
    "        'Numero nuovi outliers': numero_outliers_new,\n",
    "        'Percentuale nuovi outliers': f'{percentuale_outliers_new:.2f}%'\n",
    "    })\n",
    "\n",
    "# Converti le liste in DataFrame\n",
    "df_outliers = pd.DataFrame(risultati_outliers)\n",
    "df_nuovi_outliers = pd.DataFrame(risultati_nuovi_outliers)\n",
    "\n",
    "# Unisci i DataFrame sui risultati originali e nuovi\n",
    "outliers_summary_df = df_outliers.merge(df_nuovi_outliers, on='Colonna')\n",
    "\n",
    "# Visualizza la tabella finale\n",
    "print(outliers_summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suddivisione del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df.drop(columns=['Year'])  # Non la consideriamo per il modello\n",
    "y = clean_df['Year'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Salva il modello di scaling\n",
    "with open('scaler.save', 'wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_size = X_train.shape[0]\n",
    "test_set_size = X_test.shape[0]\n",
    "total_size = X.shape[0]\n",
    "\n",
    "print(f\"Dimensione del training set: {training_set_size} ({(training_set_size / total_size) * 100:.2f}% del dataset totale)\")\n",
    "print(f\"Dimensione del test set: {test_set_size} ({(test_set_size / total_size) * 100:.2f}% del dataset totale)\")\n",
    "# print(\"\\nDati di training normalizzati:\")\n",
    "# print(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = clean_df.drop('Year', axis=1)\n",
    "y_rf = clean_df['Year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riduzione della dimensionalit√† con PCA\n",
    "pca = PCA(n_components=0.95)  # Mantieni il 95% della varianza spiegata\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "print(f\"Numero di componenti principali: {pca.n_components_}\")\n",
    "print(f\"Forma dei dati di training dopo PCA: {X_train_pca.shape}\")\n",
    "print(f\"Forma dei dati di test dopo PCA: {X_test_pca.shape}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcolo e stampe metriche di valutazione del modello\n",
    "def valutazione_modello(y_pred, y_true):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"MSE (Mean Squared Error): {mse}\")\n",
    "    print(f\"MAE (Mean Absolute Error): {mae}\")\n",
    "    print(f\"MAPE (Mean Absolute Percentage Error): {mape}%\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "    #return mse, mae, mape, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dei parametri per il tuning\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [300, 400, 450],\n",
    "    'max_depth': [140, 160, 170], \n",
    "    'min_samples_split': [3, 5, 8],\n",
    "    'min_samples_leaf': [3, 5] \n",
    "}\n",
    "\n",
    "# Creazione del modello e GridSearchCV\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Migliori parametri trovati per Random Forest\n",
    "print(f\"Migliori parametri trovati per Random Forest: {grid_rf.best_params_}\")\n",
    "\n",
    "# Predizione\n",
    "y_pred_rf = grid_rf.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Valutazione del modello\n",
    "print(\"Risultati random forest:\")\n",
    "valutazione_modello(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set modello con migliori iperparametri\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=450,\n",
    "    max_depth=170,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=5,\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Fit del modello su tutto il df scalato\n",
    "rf.fit(X_scaled, y)\n",
    "\n",
    "# Salvataggio del modello su disco\n",
    "with open(\"rf.save\", \"wb\") as file:\n",
    "    pickle.dump(rf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsione sui dati di test con il modello RF gi√† addestrato\n",
    "y_pred_rf = grid_rf.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Creazione del grafico Valori previsione vs Valori reali\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_rf, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)  # Linea diagonale\n",
    "plt.xlabel('Valori reali')\n",
    "plt.ylabel('Valori predetti')\n",
    "plt.title('RF: valori previsione vs valori reali')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regr = LinearRegression()\n",
    "# Addestriamo modello sui dati di training\n",
    "linear_regr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predizioni sul set di test\n",
    "y_pred_lr = linear_regr.predict(X_test_scaled)\n",
    "\n",
    "# Valutazione del modello\n",
    "print(\"Risultati linear regression:\")\n",
    "valutazione_modello(y_pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_scaled, y) # Fit su tutto il df\n",
    "\n",
    "# Salvataggio del modello su disco\n",
    "with open(\"lr.save\", \"wb\") as file:\n",
    "    pickle.dump(linear_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsione sui dati di test con il modello Linear Regression gi√† addestrato\n",
    "y_pred_lr = linear_regr.predict(X_test_scaled)\n",
    "\n",
    "# Creazione del grafico Valori previsione vs Valori reali per Linear Regression\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_lr, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)  # Linea diagonale\n",
    "plt.xlabel('Valori reali')\n",
    "plt.ylabel('Valori predetti')\n",
    "plt.title('Linear Regression: valori previsione vs valori reali')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dei parametri per il tuning\n",
    "param_grid_svr = {\n",
    "    'C': [ 0.1, 0.4, 0.8],\n",
    "    'kernel': [ 'sigmoid', 'rbf',  'linear', 'poly' ],\n",
    "    'gamma': [ 'scale', 0.5 ],\n",
    "    'epsilon' : [ 0.2, 0.4, 0.5 ] \n",
    "}\n",
    "\n",
    "# Creazione del modello e GridSearchCV\n",
    "svr = SVR()\n",
    "grid_svr = GridSearchCV(estimator=svr, param_grid=param_grid_svr, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Migliori parametri trovati per SVR\n",
    "print(f\"Migliori parametri trovati per SVR: {grid_svr.best_params_}\")\n",
    "\n",
    "# Predizione\n",
    "y_pred_svr = grid_svr.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Valutazione del modello\n",
    "print(\"Risultati SVR:\")\n",
    "valutazione_modello(y_pred_svr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set migliori parametri \n",
    "best_params = {\n",
    "    'C': 0.4,\n",
    "    'kernel': 'rbf',\n",
    "    'gamma': 'scale',\n",
    "    'epsilon': 0.5\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Inizializza il modello SVR con i migliori iperparametri\n",
    "svr = SVR(**best_params)\n",
    "\n",
    "# Addestramento del modello\n",
    "svr.fit(X_scaled, y)\n",
    "\n",
    "# Salvataggio del modello su disco\n",
    "with open(\"svr.save\", \"wb\") as file:\n",
    "    pickle.dump(svr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsione sui dati di test con il modello SVR gi√† addestrato\n",
    "y_pred_svr = grid_svr.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Creazione del grafico Valori previsione vs Valori reali\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_svr, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)  # Linea diagonale\n",
    "plt.xlabel('Valori reali')\n",
    "plt.ylabel('Valori predetti')\n",
    "plt.title('SVR: valori previsione vs valori reali')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione dei parametri per il tuning\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [5, 10, 15, 17, 30, 35, 40],\n",
    "    'weights': ['distance', 'uniform'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# Creazione del modello e GridSearchCV\n",
    "knn = KNeighborsRegressor()\n",
    "grid_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Migliori parametri trovati per KNN\n",
    "print(f\"Migliori parametri trovati per KNN: {grid_knn.best_params_}\")\n",
    "\n",
    "# Predizione\n",
    "y_pred_knn = grid_knn.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Valutazione del modello\n",
    "print(\"Risultati KNN:\")\n",
    "valutazione_modello(y_pred_knn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Migliori parametri ottenuti\n",
    "best_params = {\n",
    "    'n_neighbors': 17,\n",
    "    'weights': 'distance',\n",
    "    'metric': 'manhattan'\n",
    "}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Inizializza il modello KNN con i migliori iperparametri\n",
    "knn = KNeighborsRegressor(**best_params)\n",
    "\n",
    "# Addestramento del modello\n",
    "knn.fit(X_scaled, y)\n",
    "\n",
    "# Salvataggio del modello su disco\n",
    "with open(\"knn.save\", \"wb\") as file:\n",
    "    pickle.dump(knn, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsione sui dati di test con il modello KNN gi√† addestrato\n",
    "y_pred_knn = grid_knn.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "# Creazione del grafico Valori previsione vs Valori reali\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred_knn, color='blue', alpha=0.5)\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linewidth=2)  # Linea diagonale\n",
    "plt.xlabel('Valori reali')\n",
    "plt.ylabel('Valori predetti')\n",
    "plt.title('KNN: valori previsione vs valori reali')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
